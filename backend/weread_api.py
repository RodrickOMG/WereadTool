import requests
import json
import time
from typing import Dict, List, Optional, Tuple
from collections import defaultdict
try:
    import markdown2
except ImportError:
    print("Warning: markdown2 not installed, markdown features will be limited")
    markdown2 = None

try:
    from config import settings
except ImportError:
    from config_simple import settings

requests.packages.urllib3.disable_warnings()

class WeReadAPI:
    def __init__(self, cookies: str):
        """
        åˆå§‹åŒ–å¾®ä¿¡è¯»ä¹¦APIå®¢æˆ·ç«¯
        å‚è€ƒ wereader é¡¹ç›®ï¼Œæ”¯æŒè‡ªåŠ¨è·å–çš„cookie

        Args:
            cookies: cookieå­—ç¬¦ä¸²ï¼Œæ ¼å¼ä¸º "key1=value1; key2=value2"
        """
        self.cookies = cookies

        # Webç«¯è¯·æ±‚å¤´ - æ¨¡æ‹Ÿæµè§ˆå™¨è¡Œä¸ºï¼Œç”¨äºè®¿é—®ç½‘é¡µç«¯ç‚¹
        self.headers_web = {
            'Host': 'weread.qq.com',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
            'Accept-Encoding': 'gzip, deflate, br, zstd',
            'Accept-Language': 'zh-CN,zh;q=0.9',
            'Sec-Ch-Ua': '"Chromium";v="140", "Not=A?Brand";v="24", "Google Chrome";v="140"',
            'Sec-Ch-Ua-Mobile': '?0',
            'Sec-Ch-Ua-Platform': '"Windows"',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'same-origin',
            'Sec-Fetch-User': '?1',
            'Cookie': cookies,
            'Referer': 'https://weread.qq.com/'
        }

        # APIè¯·æ±‚å¤´ - ç”¨äºè®¿é—®APIç«¯ç‚¹
        self.headers = {
            'Host': 'i.weread.qq.com',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:106.0) Gecko/20100101 Firefox/106.0',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Accept-Language': 'zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2',
            'Cookie': cookies
        }

        self.headers_post = {
            'Connection': 'keep-alive',
            'Accept': 'application/json, text/plain, */*',
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.103 Safari/537.36',
            'Content-Type': 'application/json;charset=UTF-8',
            'Origin': 'https://weread.qq.com',
            'Sec-Fetch-Site': 'same-origin',
            'Sec-Fetch-Mode': 'cors',
            'Sec-Fetch-Dest': 'empty',
            'Accept-Encoding': 'gzip, deflate, br',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Cookie': cookies
        }

    def request_data(self, url: str) -> Dict:
        """Request data from WeRead API"""
        r = requests.get(url, headers=self.headers, verify=False)
        if r.ok:
            return r.json()
        else:
            raise Exception(f"Request failed: {r.text}")

    def login_success(self) -> bool:
        """
        æ£€æŸ¥ç™»å½•æ˜¯å¦æˆåŠŸ
        ç®€åŒ–ä¸ºåŸºæœ¬çš„ç½‘é¡µè®¿é—®éªŒè¯ï¼Œé¿å…æ— æ•ˆçš„APIç«¯ç‚¹éªŒè¯
        """
        try:
            print("ğŸ” éªŒè¯ç™»å½•çŠ¶æ€: æ£€æŸ¥ç½‘é¡µè®¿é—®æƒé™")

            # åªéªŒè¯æœ€åŸºæœ¬çš„ç½‘é¡µè®¿é—®æƒé™
            r = requests.get(
                f"{settings.weread_web_url}/web/shelf",
                headers=self.headers_web,
                verify=False,
                timeout=10
            )

            if r.status_code == 200:
                # æ£€æŸ¥æ˜¯å¦è¿”å›HTMLé¡µé¢ä¸”åŒ…å«å¾®ä¿¡è¯»ä¹¦ç›¸å…³å†…å®¹
                content_type = r.headers.get('content-type', '')
                if 'text/html' in content_type:
                    html_content = r.text.lower()
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«å¾®ä¿¡è¯»ä¹¦ç›¸å…³å…³é”®è¯
                    if any(keyword in html_content for keyword in ['weread', 'è¯»ä¹¦', 'å¾®ä¿¡è¯»ä¹¦', 'book', 'shelf']):
                        print("âœ… ç™»å½•éªŒè¯æˆåŠŸï¼šèƒ½å¤Ÿæ­£å¸¸è®¿é—®å¾®ä¿¡è¯»ä¹¦é¡µé¢")
                        return True
                    else:
                        print("âš ï¸ é¡µé¢å†…å®¹å¼‚å¸¸ï¼Œå¯èƒ½æœªæ­£ç¡®ç™»å½•")
                        return False
                else:
                    print("âœ… ç™»å½•éªŒè¯æˆåŠŸï¼šAPIå“åº”æ­£å¸¸")
                    return True

            elif r.status_code in [401, 403]:
                print(f"âŒ ç™»å½•éªŒè¯å¤±è´¥ï¼šè®¤è¯é”™è¯¯ {r.status_code}")
                return False

            elif r.status_code == 404:
                print("âš ï¸ ç«¯ç‚¹ä¸å­˜åœ¨ï¼Œä½†å¯èƒ½ç™»å½•çŠ¶æ€æ­£å¸¸")
                # 404ä¸ä¸€å®šè¡¨ç¤ºç™»å½•å¤±è´¥ï¼Œå¯èƒ½æ˜¯ç«¯ç‚¹å˜æ›´
                return True

            else:
                print(f"âš ï¸ å¼‚å¸¸çŠ¶æ€ç  {r.status_code}ï¼Œå°è¯•å…¶ä»–éªŒè¯æ–¹å¼")
                return False

        except requests.exceptions.Timeout:
            print("âš ï¸ è¯·æ±‚è¶…æ—¶ï¼Œç½‘ç»œå¯èƒ½å­˜åœ¨é—®é¢˜")
            return False
        except requests.exceptions.ConnectionError:
            print("âš ï¸ è¿æ¥é”™è¯¯ï¼Œæ— æ³•è®¿é—®å¾®ä¿¡è¯»ä¹¦")
            return False
        except Exception as e:
            print(f"âš ï¸ éªŒè¯è¿‡ç¨‹å‡ºé”™: {e}")
            return False

    def get_user_data(self, user_vid: str) -> Dict:
        """Get user's bookshelf data using multiple fallback APIs"""
        fallback_apis = [
            {
                "name": "web_shelf_new",
                "url": f"{settings.weread_web_url}/web/shelf",
                "method": "GET",
                "headers": self.headers_web,
                "timeout": 15
            },
            {
                "name": "web_bookshelf",
                "url": f"{settings.weread_web_url}/web/bookshelf",
                "method": "GET",
                "headers": self.headers_web,
                "timeout": 15
            },
            {
                "name": "shelf_sync_old",
                "url": f"{settings.weread_base_url}/shelf/sync?userVid={user_vid}&synckey=0&lectureSynckey=0",
                "method": "GET",
                "headers": self.headers,
                "timeout": 15
            },
            {
                "name": "user_bookshelf",
                "url": f"{settings.weread_base_url}/user/bookshelf?userVid={user_vid}",
                "method": "GET",
                "headers": self.headers,
                "timeout": 15
            },
            {
                "name": "web_shelf_minimal",
                "url": f"{settings.weread_web_url}/web/shelf?minimal=1",
                "method": "GET",
                "headers": self.headers_web,
                "timeout": 10
            }
        ]

        last_error = None
        for api_config in fallback_apis:
            try:
                print(f"ğŸ”„ å°è¯•API: {api_config['name']} - {api_config['url']}")

                headers = api_config.get('headers', self.headers)

                if api_config['method'] == 'GET':
                    r = requests.get(
                        api_config['url'],
                        headers=headers,
                        verify=False,
                        timeout=api_config['timeout']
                    )
                else:
                    r = requests.post(
                        api_config['url'],
                        headers=headers,
                        verify=False,
                        timeout=api_config['timeout']
                    )

                if r.status_code == 200:
                    # æ£€æŸ¥å“åº”å†…å®¹ç±»å‹
                    content_type = r.headers.get('content-type', '')

                    if 'text/html' in content_type:
                        # HTMLå“åº” - å°è¯•è§£æé¡µé¢ä¸­çš„æ•°æ®
                        print(f"âœ… {api_config['name']} è¿”å›HTMLå“åº”ï¼Œå°è¯•è§£ææ•°æ®")
                        html_content = r.text

                        # å°è¯•ä»HTMLä¸­æå–ä¹¦ç±æ•°æ®
                        books_data = self._extract_books_from_html(html_content, user_vid)
                        if books_data:
                            print(f"âœ… ä»HTMLä¸­æå–åˆ° {len(books_data)} æœ¬ä¹¦ç±")
                            return {
                                "books": books_data,
                                "user_vid": user_vid,
                                "source": api_config['name'] + "_html_parsed"
                            }
                        else:
                            # æ— æ³•è§£æHTMLï¼Œä½†é¡µé¢è®¿é—®æˆåŠŸ
                            return {
                                "books": [],
                                "user_vid": user_vid,
                                "source": api_config['name'] + "_html_no_data",
                                "html_content": html_content[:1000]  # ä¿å­˜éƒ¨åˆ†HTMLç”¨äºè°ƒè¯•
                            }
                    else:
                        # JSONå“åº”
                        try:
                            data = r.json()
                            print(f"âœ… {api_config['name']} APIè°ƒç”¨æˆåŠŸ")
                            return data
                        except ValueError as json_error:
                            print(f"âš ï¸ {api_config['name']} è¿”å›çš„ä¸æ˜¯æœ‰æ•ˆJSON: {json_error}")
                            # å¦‚æœä¸æ˜¯JSONä½†çŠ¶æ€ç æ˜¯200ï¼Œå¯èƒ½æ˜¯ä¸€ä¸ªç‰¹æ®Šå“åº”
                            return {
                                "books": [],
                                "user_vid": user_vid,
                                "source": api_config['name'] + "_non_json",
                                "raw_response": r.text[:200]
                            }

                elif r.status_code in [401, 403]:
                    # è®¤è¯ç›¸å…³é”™è¯¯ï¼Œè®°å½•ä½†ç»§ç»­å°è¯•å…¶ä»–API
                    error_msg = f"è®¤è¯å¤±è´¥ {r.status_code}: {api_config['name']}"
                    print(f"âš ï¸ {error_msg}")
                    last_error = Exception(error_msg)
                    continue

                elif r.status_code == 404:
                    # ç«¯ç‚¹ä¸å­˜åœ¨ï¼Œç»§ç»­å°è¯•å…¶ä»–API
                    print(f"âš ï¸ ç«¯ç‚¹ä¸å­˜åœ¨ 404: {api_config['name']}")
                    continue

                else:
                    # å…¶ä»–é”™è¯¯çŠ¶æ€ç 
                    error_msg = f"APIè¿”å›å¼‚å¸¸çŠ¶æ€ç  {r.status_code}: {api_config['name']}"
                    print(f"âš ï¸ {error_msg}")
                    last_error = Exception(error_msg)
                    continue

            except requests.exceptions.Timeout:
                print(f"âš ï¸ è¯·æ±‚è¶…æ—¶: {api_config['name']}")
                continue
            except requests.exceptions.ConnectionError:
                print(f"âš ï¸ è¿æ¥é”™è¯¯: {api_config['name']}")
                continue
            except Exception as e:
                error_msg = f"{api_config['name']} è°ƒç”¨å‡ºé”™: {str(e)}"
                print(f"âš ï¸ {error_msg}")
                last_error = e
                continue

        # æ‰€æœ‰APIéƒ½å¤±è´¥äº†
        error_msg = "æ‰€æœ‰ä¹¦æ¶APIéƒ½è°ƒç”¨å¤±è´¥ï¼Œæœ€åé”™è¯¯: " + str(last_error) if last_error else "æœªçŸ¥é”™è¯¯"
        print(f"âŒ {error_msg}")
        raise Exception(error_msg)

    def _extract_books_from_html(self, html_content: str, user_vid: str) -> List[Dict]:
        """
        ä»HTMLé¡µé¢ä¸­æå–ä¹¦ç±æ•°æ®
        åˆ†æå¾®ä¿¡è¯»ä¹¦é¡µé¢çš„ç»“æ„ï¼Œå¯»æ‰¾ä¹¦ç±ç›¸å…³çš„æ•°æ®
        """
        try:
            import re
            import json
            from typing import List, Dict

            books = []
            print(f"ğŸ” å¼€å§‹è§£æHTMLä¹¦æ¶æ•°æ®ï¼Œå†…å®¹é•¿åº¦: {len(html_content)}")

            # æ–¹æ³•1: æŸ¥æ‰¾JavaScriptä¸­çš„ä¹¦ç±æ•°æ®ï¼ˆæ›´åŠ å…¨é¢çš„æ¨¡å¼ï¼‰
            js_patterns = [
                # å¸¸è§çš„ä¹¦ç±æ•°æ®æ¨¡å¼
                r'books\s*:\s*(\[[\s\S]*?\])',  # books: [...]
                r'"books"\s*:\s*(\[[\s\S]*?\])',  # "books": [...]
                r'bookList\s*:\s*(\[[\s\S]*?\])',  # bookList: [...]
                r'shelfData\s*:\s*(\[[\s\S]*?\])',  # shelfData: [...]
                r'shelf\s*:\s*\{[^}]*books\s*:\s*(\[[\s\S]*?\])',  # shelf: {books: [...]}
                r'data\s*:\s*\{[^}]*books\s*:\s*(\[[\s\S]*?\])',  # data: {books: [...]}
                # æ›´å…·ä½“çš„å¾®ä¿¡è¯»ä¹¦æ¨¡å¼
                r'window\.__INITIAL_STATE__\s*=\s*\{[\s\S]*?"books"\s*:\s*(\[[\s\S]*?\])',
                r'window\.preloadedData\s*=\s*[\s\S]*?"books"\s*:\s*(\[[\s\S]*?\])',
                r'__NUXT__\s*=\s*[\s\S]*?"books"\s*:\s*(\[[\s\S]*?\])'
            ]

            for pattern in js_patterns:
                try:
                    matches = re.findall(pattern, html_content, re.DOTALL | re.IGNORECASE)
                    for match in matches:
                        try:
                            # å°è¯•è§£æJSONæ•°æ®
                            match = match.strip()
                            if match.startswith('[') and match.endswith(']'):
                                book_list = json.loads(match)
                                if isinstance(book_list, list) and book_list:
                                    print(f"âœ… æ‰¾åˆ°JSä¹¦ç±æ•°æ®ï¼Œæ•°é‡: {len(book_list)}")
                                    for book in book_list:
                                        if isinstance(book, dict) and book.get('bookId'):
                                            books.append(self._normalize_book_data(book))
                        except (json.JSONDecodeError, ValueError) as e:
                            continue
                except Exception as e:
                    continue

            # æ–¹æ³•2: æŸ¥æ‰¾æ›´å…·ä½“çš„ä¹¦ç±IDå’Œä¿¡æ¯æ¨¡å¼
            if not books:
                print("ğŸ” JSè§£ææ— ç»“æœï¼Œå°è¯•HTMLå…ƒç´ è§£æ")
                
                # æ›´ç²¾ç¡®çš„ä¹¦ç±IDæ¨¡å¼
                book_patterns = [
                    r'data-book-id=["\']([^"\']+)["\']',  # data-book-id="..."
                    r'data-bookid=["\']([^"\']+)["\']',   # data-bookid="..."
                    r'bookId["\']?\s*[:=]\s*["\']([a-zA-Z0-9_-]{6,})["\']',  # bookId: "..."
                    r'/book/([a-zA-Z0-9_-]{6,})',         # /book/bookId
                    r'weread\.qq\.com/web/reader/([a-zA-Z0-9_-]{6,})',  # reader links
                ]
                
                # æå–ä¹¦ç±æ ‡é¢˜æ¨¡å¼
                title_patterns = [
                    r'data-title=["\']([^"\']+)["\']',
                    r'title=["\']([^"\']+)["\']',
                    r'alt=["\']([^"\']+)["\']'
                ]

                book_ids = set()
                for pattern in book_patterns:
                    matches = re.findall(pattern, html_content, re.IGNORECASE)
                    for match in matches:
                        if match and len(match) >= 6 and not match.startswith('http'):
                            book_ids.add(match)

                if book_ids:
                    print(f"âœ… ä»HTMLä¸­æ‰¾åˆ° {len(book_ids)} ä¸ªä¹¦ç±ID")
                    for book_id in book_ids:
                        books.append({
                            "bookId": book_id,
                            "title": self._extract_book_title(html_content, book_id) or f"ä¹¦ç±-{book_id[:8]}",
                            "author": "å¾…è·å–",
                            "cover": self._extract_book_cover(html_content, book_id) or "",
                            "category": "",
                            "finishReading": 0,
                            "newRatingDetail": "",
                            "readUpdateTime": int(time.time() * 1000),
                            "source": "html_element_parsed"
                        })

            # æ–¹æ³•3: æŸ¥æ‰¾ä¹¦æ¶ç›¸å…³çš„JSONæ•°æ®
            if not books:
                print("ğŸ” å°è¯•æŸ¥æ‰¾å†…åµŒçš„JSONæ•°æ®")
                json_patterns = [
                    r'<script[^>]*type=["\']application/json["\'][^>]*>([\s\S]*?)</script>',
                    r'<script[^>]*>([\s\S]*?window\.__.*?=[\s\S]*?)</script>',
                ]
                
                for pattern in json_patterns:
                    matches = re.findall(pattern, html_content, re.DOTALL)
                    for match in matches:
                        try:
                            # å°è¯•æå–å…¶ä¸­çš„ä¹¦ç±ä¿¡æ¯
                            if 'book' in match.lower() and 'id' in match.lower():
                                book_refs = re.findall(r'"([a-zA-Z0-9_-]{6,})"', match)
                                for book_id in book_refs:
                                    if len(book_id) >= 6 and book_id not in [b.get('bookId') for b in books]:
                                        books.append({
                                            "bookId": book_id,
                                            "title": f"ä¹¦ç±-{book_id[:8]}",
                                            "author": "å¾…è·å–",
                                            "cover": "",
                                            "category": "",
                                            "finishReading": 0,
                                            "newRatingDetail": "",
                                            "readUpdateTime": int(time.time() * 1000),
                                            "source": "json_script_parsed"
                                        })
                        except Exception:
                            continue

            # å»é‡å’Œæ¸…ç†
            seen_ids = set()
            unique_books = []
            for book in books:
                book_id = book.get('bookId', '')
                if book_id and book_id not in seen_ids and len(book_id) >= 6:
                    seen_ids.add(book_id)
                    unique_books.append(book)

            print(f"ğŸ“š HTMLè§£æå®Œæˆï¼Œæå–åˆ° {len(unique_books)} æœ¬ä¹¦ç±")
            
            # å¦‚æœä»ç„¶æ²¡æœ‰æ‰¾åˆ°ä¹¦ç±ï¼Œè¾“å‡ºè°ƒè¯•ä¿¡æ¯
            if not unique_books:
                print("âš ï¸ æœªæ‰¾åˆ°ä¹¦ç±æ•°æ®ï¼Œè¾“å‡ºHTMLç‰‡æ®µç”¨äºè°ƒè¯•:")
                preview = html_content[:500].replace('\n', ' ')
                print(f"HTMLé¢„è§ˆ: {preview}...")
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«ç™»å½•ç›¸å…³çš„å…³é”®è¯
                if any(keyword in html_content.lower() for keyword in ['login', 'ç™»å½•', 'scan', 'æ‰«ç ']):
                    print("ğŸ’¡ æ£€æµ‹åˆ°ç™»å½•é¡µé¢ï¼Œå¯èƒ½éœ€è¦é‡æ–°ç™»å½•")

            return unique_books[:100]  # å¢åŠ åˆ°100æœ¬ä¹¦çš„é™åˆ¶

        except Exception as e:
            print(f"âŒ HTMLè§£æå‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            return []

    def _normalize_book_data(self, book_data: Dict) -> Dict:
        """æ ‡å‡†åŒ–ä¹¦ç±æ•°æ®æ ¼å¼"""
        return {
            "bookId": book_data.get('bookId', book_data.get('id', '')),
            "title": book_data.get('title', book_data.get('name', 'æœªçŸ¥ä¹¦ç±')),
            "author": book_data.get('author', book_data.get('authors', 'æœªçŸ¥ä½œè€…')),
            "cover": book_data.get('cover', book_data.get('coverUrl', '')),
            "category": book_data.get('category', book_data.get('categoryName', '')),
            "finishReading": book_data.get('finishReading', book_data.get('isFinished', 0)),
            "newRatingDetail": book_data.get('newRatingDetail', book_data.get('rating', '')),
            "readUpdateTime": book_data.get('readUpdateTime', book_data.get('updateTime', int(time.time() * 1000))),
            "source": "js_data_parsed"
        }

    def _extract_book_title(self, html_content: str, book_id: str) -> str:
        """ä»HTMLä¸­æå–ç‰¹å®šä¹¦ç±çš„æ ‡é¢˜"""
        try:
            import re
            # åœ¨ä¹¦ç±IDé™„è¿‘æŸ¥æ‰¾æ ‡é¢˜
            patterns = [
                rf'{re.escape(book_id)}[^>]*[^>]*title=["\']([^"\']+)["\']',
                rf'title=["\']([^"\']+)["\'][^>]*{re.escape(book_id)}',
                rf'{re.escape(book_id)}[^>]*>([^<]+)<',
            ]
            
            for pattern in patterns:
                match = re.search(pattern, html_content, re.IGNORECASE)
                if match:
                    return match.group(1).strip()
            return ""
        except Exception:
            return ""

    def _extract_book_cover(self, html_content: str, book_id: str) -> str:
        """ä»HTMLä¸­æå–ç‰¹å®šä¹¦ç±çš„å°é¢"""
        try:
            import re
            # åœ¨ä¹¦ç±IDé™„è¿‘æŸ¥æ‰¾å°é¢å›¾ç‰‡
            patterns = [
                rf'{re.escape(book_id)}[^>]*[^>]*src=["\']([^"\']+)["\']',
                rf'src=["\']([^"\']*{re.escape(book_id)}[^"\']*)["\']',
            ]
            
            for pattern in patterns:
                match = re.search(pattern, html_content, re.IGNORECASE)
                if match:
                    return match.group(1).strip()
            return ""
        except Exception:
            return ""

    def get_book_info(self, book_id: str) -> Dict:
        """Get book information with fallback support"""
        fallback_urls = [
            f"{settings.weread_base_url}/book/info?bookId={book_id}",
            f"{settings.weread_base_url}/web/book/info?bookId={book_id}",
            f"{settings.weread_base_url}/book/detail?bookId={book_id}"
        ]

        last_error = None
        for url in fallback_urls:
            try:
                print(f"ğŸ”„ è·å–ä¹¦ç±ä¿¡æ¯: {book_id} - {url.split('/')[-1]}")
                r = requests.get(url, headers=self.headers, verify=False, timeout=10)

                if r.status_code == 200:
                    try:
                        data = r.json()
                        print(f"âœ… ä¹¦ç±ä¿¡æ¯è·å–æˆåŠŸ: {book_id}")
                        return data
                    except ValueError as json_error:
                        # æ£€æŸ¥æ˜¯å¦ä¸ºHTMLå“åº”
                        content_type = r.headers.get('content-type', '')
                        if 'text/html' in content_type:
                            print(f"ğŸ“„ ä¹¦ç±ä¿¡æ¯è¿”å›HTMLé¡µé¢: {book_id}")
                            # è¿”å›åŸºç¡€ä¹¦ç±ä¿¡æ¯ï¼Œé¿å…æŠ›å‡ºå¼‚å¸¸
                            return {
                                "bookId": book_id,
                                "title": "ä¹¦ç±ä¿¡æ¯ä¸å¯ç”¨",
                                "author": "æœªçŸ¥",
                                "cover": "",
                                "intro": "è¯¥ä¹¦ç±ä¿¡æ¯æš‚æ—¶æ— æ³•è·å–",
                                "publisher": "",
                                "category": "",
                                "finishReading": 0,
                                "newRatingDetail": {"title": ""},
                                "source": "html_response"
                            }
                        else:
                            print(f"âš ï¸ ä¹¦ç±ä¿¡æ¯è¿”å›çš„ä¸æ˜¯æœ‰æ•ˆJSON: {json_error}")
                            last_error = json_error
                            continue
                elif r.status_code == 404:
                    print(f"âš ï¸ ä¹¦ç±ä¸å­˜åœ¨ 404: {book_id}")
                    # ä¹¦ç±ä¸å­˜åœ¨æ—¶è¿”å›åŸºç¡€ä¿¡æ¯è€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸
                    return {
                        "bookId": book_id,
                        "title": "ä¹¦ç±ä¿¡æ¯ä¸å¯ç”¨",
                        "author": "æœªçŸ¥",
                        "cover": "",
                        "intro": "è¯¥ä¹¦ç±ä¿¡æ¯æš‚æ—¶æ— æ³•è·å–",
                        "category": "",
                        "publisher": "",
                        "finishReading": 0,
                        "newRatingDetail": {"title": ""},
                        "error": "ä¹¦ç±ä¿¡æ¯ä¸å¯ç”¨"
                    }
                else:
                    error_msg = f"è·å–ä¹¦ç±ä¿¡æ¯å¤±è´¥ {r.status_code}: {book_id}"
                    print(f"âš ï¸ {error_msg}")
                    last_error = Exception(error_msg)
                    continue

            except Exception as e:
                print(f"âš ï¸ è·å–ä¹¦ç±ä¿¡æ¯å‡ºé”™: {book_id} - {e}")
                last_error = e
                continue

        # æ‰€æœ‰URLéƒ½å¤±è´¥äº†
        error_msg = f"æ— æ³•è·å–ä¹¦ç±ä¿¡æ¯ {book_id}: {str(last_error) if last_error else 'æœªçŸ¥é”™è¯¯'}"
        print(f"âŒ {error_msg}")
        raise Exception(error_msg)

    def get_sorted_chapters(self, book_id: str) -> List[Tuple]:
        """Get sorted chapters of a book"""
        if '_' in book_id:
            return []  # WeChat articles not supported

        url = f"{settings.weread_base_url}/book/chapterInfos?bookIds={book_id}&synckeys=0"
        data = self.request_data(url)
        chapters = []

        for item in data['data'][0]['updated']:
            try:
                chapters.append((item['chapterUid'], item['level'], item['title']))
            except:
                chapters.append((item['chapterUid'], 1, item['title']))

        return chapters

    def get_bookmarks(self, book_id: str) -> Dict:
        """Get bookmarks/notes for a book with fallback support"""
        fallback_urls = [
            f"{settings.weread_base_url}/book/bookmarklist?bookId={book_id}",
            f"{settings.weread_base_url}/web/book/bookmarklist?bookId={book_id}",
            f"{settings.weread_base_url}/bookmarks/list?bookId={book_id}"
        ]

        last_error = None
        for url in fallback_urls:
            try:
                print(f"ğŸ”„ è·å–ä¹¦ç­¾: {book_id} - {url.split('/')[-1]}")
                r = requests.get(url, headers=self.headers, verify=False, timeout=15)

                if r.status_code == 200:
                    try:
                        data = r.json()
                        # æ£€æŸ¥æ•°æ®ç»“æ„æ˜¯å¦æ­£ç¡®
                        if isinstance(data, dict) and ('updated' in data or 'bookmarks' in data or 'data' in data):
                            print(f"âœ… ä¹¦ç­¾è·å–æˆåŠŸ: {book_id}")
                            return data
                        else:
                            print(f"âš ï¸ ä¹¦ç­¾æ•°æ®ç»“æ„å¼‚å¸¸: {book_id}")
                            last_error = Exception("æ•°æ®ç»“æ„å¼‚å¸¸")
                            continue
                    except ValueError as json_error:
                        # æ£€æŸ¥æ˜¯å¦ä¸ºHTMLå“åº”
                        content_type = r.headers.get('content-type', '')
                        if 'text/html' in content_type:
                            print(f"ğŸ“„ ä¹¦ç­¾è¿”å›HTMLé¡µé¢: {book_id}")
                            # è¿”å›ç©ºä¹¦ç­¾æ•°æ®ï¼Œé¿å…æŠ›å‡ºå¼‚å¸¸
                            return {
                                "book": {"bookId": book_id},
                                "updated": [],
                                "source": "html_response",
                                "error": "ä¹¦ç­¾åŠŸèƒ½æš‚æ—¶ä¸å¯ç”¨ï¼Œè¿”å›HTMLé¡µé¢"
                            }
                        else:
                            print(f"âš ï¸ ä¹¦ç­¾æ•°æ®è¿”å›çš„ä¸æ˜¯æœ‰æ•ˆJSON: {json_error}")
                            last_error = json_error
                            continue
                elif r.status_code == 404:
                    print(f"âš ï¸ ä¹¦ç±ä¸å­˜åœ¨æˆ–æ— ä¹¦ç­¾ 404: {book_id}")
                    # è¿”å›ç©ºä¹¦ç­¾æ•°æ®è€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸
                    return {
                        "book": {"bookId": book_id},
                        "updated": [],
                        "error": "ä¹¦ç±ä¸å­˜åœ¨æˆ–æ— ä¹¦ç­¾"
                    }
                else:
                    error_msg = f"è·å–ä¹¦ç­¾å¤±è´¥ {r.status_code}: {book_id}"
                    print(f"âš ï¸ {error_msg}")
                    last_error = Exception(error_msg)
                    continue

            except Exception as e:
                print(f"âš ï¸ è·å–ä¹¦ç­¾å‡ºé”™: {book_id} - {e}")
                last_error = e
                continue

        # æ‰€æœ‰URLéƒ½å¤±è´¥äº†ï¼Œè¿”å›ç©ºæ•°æ®ç»“æ„è€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸
        print(f"âŒ æ— æ³•è·å–ä¹¦ç­¾ {book_id}: {str(last_error) if last_error else 'æœªçŸ¥é”™è¯¯'}")
        return {
            "book": {"bookId": book_id},
            "updated": [],
            "error": f"æ— æ³•è·å–ä¹¦ç­¾: {str(last_error) if last_error else 'æœªçŸ¥é”™è¯¯'}"
        }

    def get_sorted_contents_from_data(self, data: Dict) -> Dict:
        """Process bookmark data and sort by chapter and position"""
        book_id = data['book']['bookId']

        # Handle WeChat articles
        if '_' in book_id:
            return {}  # Simplified for now

        contents = defaultdict(list)

        for item in data['updated']:
            chapter_uid = item['chapterUid']
            text = item['markText']
            text_position = int(item['range'].split('-')[0])
            text_style = item['style']
            contents[chapter_uid].append([text_position, text_style, text])

        # Sort contents by position within each chapter
        sorted_contents = defaultdict(list)
        for chapter_uid in contents.keys():
            sorted_contents[chapter_uid] = sorted(contents[chapter_uid], key=lambda x: x[0])

        return sorted_contents

    def set_content_style(self, style: int, text: str) -> str:
        """Apply styling to content based on highlight style"""
        style_map = {
            0: {'pre': "", 'suf': ""},  # Red underline
            1: {'pre': "**", 'suf': "**"},  # Orange background (bold)
            2: {'pre': "", 'suf': ""}  # Blue wavy line
        }
        style_config = style_map.get(style, style_map[0])
        return style_config['pre'] + text.strip() + style_config['suf']

    def set_chapter_level(self, level: int) -> str:
        """Set chapter heading level"""
        level_map = {
            1: '## ',
            2: '### ',
            3: '#### '
        }
        return level_map.get(level, '## ')

    def get_markdown_content(self, book_id: str, is_all_chapter: int = 1) -> str:
        """Generate markdown content from bookmarks"""
        try:
            # Get bookmark data
            bookmark_data = self.get_bookmarks(book_id)

            if '_' in book_id:
                return ""  # WeChat articles not fully supported

            # Get chapters and contents
            sorted_chapters = self.get_sorted_chapters(book_id)
            sorted_contents = self.get_sorted_contents_from_data(bookmark_data)

            res = '\n'

            # Iterate through chapters
            for chapter in sorted_chapters:
                # Skip chapters without bookmarks if requested
                if is_all_chapter <= 0 and len(sorted_contents[chapter[0]]) == 0:
                    continue

                # Add chapter title
                title = chapter[2]
                res += self.set_chapter_level(chapter[1]) + title + '\n\n'

                # Add bookmarks for this chapter
                for text in sorted_contents[chapter[0]]:
                    res += self.set_content_style(text[1], text[2]) + '\n\n'

            return res

        except Exception as e:
            raise Exception(f"Failed to get markdown content: {str(e)}")

    def search_books(self, user_data: Dict, query: str) -> List[Dict]:
        """
        åœ¨ç”¨æˆ·ä¹¦åº“ä¸­æœç´¢ä¹¦ç±
        å‚è€ƒ wereader é¡¹ç›®çš„æœç´¢å®ç°
        """
        try:
            from fuzzywuzzy import fuzz
        except ImportError:
            print("Warning: fuzzywuzzy not installed, using simple string matching")
            # ç®€å•çš„å­—ç¬¦ä¸²åŒ¹é…ä½œä¸ºfallback
            results = []
            for book in user_data.get('books', []):
                title = book.get('title', '')
                if query.lower() in title.lower():
                    results.append({
                        'bookId': book['bookId'],
                        'title': title,
                        'author': book.get('author', ''),
                        'cover': book.get('cover', '').replace('s_', 't7_'),
                        'ratio': 80  # å›ºå®šè¯„åˆ†
                    })
            return results

        results = []

        for book in user_data.get('books', []):
            title = book.get('title', '')
            ratio = fuzz.partial_ratio(title, query)

            if ratio > 60:  # Lowered threshold for better results
                results.append({
                    'bookId': book['bookId'],
                    'title': title,
                    'author': book.get('author', ''),
                    'cover': book.get('cover', '').replace('s_', 't7_'),
                    'ratio': ratio
                })

        # Sort by relevance
        results.sort(key=lambda x: x['ratio'], reverse=True)
        return results
    
    @staticmethod
    def format_cookies_from_dict(cookie_dict: Dict) -> str:
        """
        å°†cookieå­—å…¸æ ¼å¼åŒ–ä¸ºå­—ç¬¦ä¸²
        å‚è€ƒ wereader é¡¹ç›®çš„cookieå¤„ç†æ–¹å¼
        """
        return '; '.join([f'{key}={value}' for key, value in cookie_dict.items()])
    
    @staticmethod
    def parse_cookies_from_string(cookie_string: str) -> Dict:
        """
        ä»cookieå­—ç¬¦ä¸²è§£æä¸ºå­—å…¸
        å‚è€ƒ wereader é¡¹ç›®çš„cookieè§£ææ–¹å¼
        å¯¹URLç¼–ç çš„å€¼è¿›è¡Œè§£ç å¤„ç†
        """
        import urllib.parse

        cookies = {}
        for item in cookie_string.split(';'):
            if '=' in item:
                key, value = item.strip().split('=', 1)
                # å¯¹URLç¼–ç çš„å€¼è¿›è¡Œè§£ç 
                cookies[key] = urllib.parse.unquote(value)

        return cookies