# å‚è€ƒ mcp-server-weread é¡¹ç›®çš„Cookieç®¡ç†å®ç°
import requests
import json
import os
from typing import Dict, Optional, Tuple
from datetime import datetime, timedelta


class CookieManager:
    """å¾®ä¿¡è¯»ä¹¦Cookieç®¡ç†å™¨ï¼Œå‚è€ƒmcp-server-wereadé¡¹ç›®å®ç°"""
    
    def __init__(self):
        self.weread_base_url = "https://i.weread.qq.com"
        self.cookie_cache = {}
        self.cache_expiry = {}
    
    def parse_cookie_string(self, cookie_string: str) -> Dict[str, str]:
        """
        è§£æCookieå­—ç¬¦ä¸²ä¸ºå­—å…¸
        å‚è€ƒmcp-server-wereadçš„è§£ææ–¹å¼
        """
        cookies = {}
        
        # æ¸…ç†Cookieå­—ç¬¦ä¸²
        cookie_string = cookie_string.strip()
        
        # åˆ†å‰²Cookieé¡¹ç›®
        cookie_items = cookie_string.split(';')
        
        for item in cookie_items:
            item = item.strip()
            if '=' in item:
                key, value = item.split('=', 1)
                key = key.strip()
                value = value.strip()
                
                # åªä¿ç•™å¾®ä¿¡è¯»ä¹¦ç›¸å…³çš„cookies
                if key.startswith('wr_') or key in ['vid', 'skey', 'gid']:
                    cookies[key] = value
        
        return cookies
    
    def validate_cookie_format(self, cookies: Dict[str, str]) -> Tuple[bool, str]:
        """
        éªŒè¯Cookieæ ¼å¼æ˜¯å¦å®Œæ•´
        å‚è€ƒmcp-server-wereadçš„éªŒè¯é€»è¾‘
        """
        required_fields = ['wr_gid', 'wr_vid', 'wr_skey', 'wr_rt']
        missing_fields = []
        
        for field in required_fields:
            if field not in cookies or not cookies[field]:
                missing_fields.append(field)
        
        if missing_fields:
            return False, f"ç¼ºå°‘å¿…è¦çš„Cookieå­—æ®µ: {', '.join(missing_fields)}"
        
        # åŸºæœ¬æ ¼å¼éªŒè¯
        if not cookies['wr_vid'].isdigit():
            return False, "wr_vidæ ¼å¼ä¸æ­£ç¡®ï¼Œåº”ä¸ºæ•°å­—"
        
        return True, "Cookieæ ¼å¼éªŒè¯é€šè¿‡"
    
    def test_cookie_validity(self, cookie_string: str) -> Tuple[bool, str, Dict]:
        """
        æµ‹è¯•Cookieæ˜¯å¦æœ‰æ•ˆ
        å‚è€ƒmcp-server-wereadçš„éªŒè¯æ–¹å¼
        """
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
                'Accept-Language': 'zh-CN,zh;q=0.9',
                'Accept-Encoding': 'gzip, deflate, br, zstd',
                'Sec-Ch-Ua': '"Chromium";v="140", "Not=A?Brand";v="24", "Google Chrome";v="140"',
                'Sec-Ch-Ua-Mobile': '?0',
                'Sec-Ch-Ua-Platform': '"Windows"',
                'Sec-Fetch-Dest': 'document',
                'Sec-Fetch-Mode': 'navigate',
                'Sec-Fetch-Site': 'same-origin',
                'Cookie': cookie_string,
                'Referer': 'https://weread.qq.com/'
            }
            
            # ä½¿ç”¨æ–°çš„web shelf APIè¿›è¡ŒéªŒè¯
            test_url = f"https://weread.qq.com/web/shelf"
            response = requests.get(test_url, headers=headers, timeout=15, verify=False)
            
            if response.status_code == 200:
                try:
                    # æ£€æŸ¥æ˜¯å¦ä¸ºHTMLå“åº”
                    if 'text/html' in response.headers.get('content-type', ''):
                        # HTMLå“åº”ï¼Œæ£€æŸ¥ç™»å½•çŠ¶æ€
                        if 'wr_vid' in response.text or 'bookshelf' in response.text:
                            # ä»Cookieä¸­æå–ç”¨æˆ·ä¿¡æ¯ï¼Œè¿›è¡ŒURLè§£ç 
                            cookies = {}
                            for item in cookie_string.split(';'):
                                if '=' in item:
                                    key, value = item.strip().split('=', 1)
                                    cookies[key] = value

                            # å¯¹URLç¼–ç çš„å€¼è¿›è¡Œè§£ç ï¼Œå¹¶è¿›è¡Œæ›´å®‰å…¨çš„å¤„ç†
                            import urllib.parse
                            def safe_unquote(value: str) -> str:
                                """å®‰å…¨åœ°è¿›è¡ŒURLè§£ç """
                                if not value:
                                    return ''
                                try:
                                    # å°è¯•å¤šç§è§£ç æ–¹å¼
                                    decoded = urllib.parse.unquote(value, encoding='utf-8')
                                    # å¦‚æœè§£ç åçš„å­—ç¬¦ä¸²ä¸åŸå­—ç¬¦ä¸²ç›¸åŒï¼Œå°è¯•å…¶ä»–ç¼–ç 
                                    if decoded == value and '%' in value:
                                        decoded = urllib.parse.unquote(value, encoding='gbk', errors='ignore')
                                    return decoded
                                except Exception:
                                    return value

                            user_info = {
                                'vid': cookies.get('wr_vid', ''),
                                'name': safe_unquote(cookies.get('wr_name', '')),
                                'avatar': safe_unquote(cookies.get('wr_avatar', '')),
                                'gender': cookies.get('wr_gender', ''),
                                'localvid': cookies.get('wr_localvid', ''),
                                'gid': cookies.get('wr_gid', ''),
                                'skey': cookies.get('wr_skey', ''),
                                'rt': cookies.get('wr_rt', '')
                            }
                            print(f"âœ… æå–ç”¨æˆ·ä¿¡æ¯: {user_info['name']} (vid: {user_info['vid']})")
                            return True, "CookieéªŒè¯æˆåŠŸ", user_info
                        else:
                            return False, "Cookieæ— æ•ˆæˆ–éœ€è¦é‡æ–°ç™»å½•", {}
                    else:
                        # JSONå“åº”
                        user_info = response.json()
                        if user_info and isinstance(user_info, dict):
                            return True, "CookieéªŒè¯æˆåŠŸ", user_info
                        else:
                            return False, "Cookieæœ‰æ•ˆä½†æ— æ³•è·å–ç”¨æˆ·ä¿¡æ¯", {}
                except Exception as e:
                    # å³ä½¿è§£æå¤±è´¥ï¼Œä½†å“åº”200ä»ç„¶è¡¨ç¤ºCookieå¯èƒ½æœ‰æ•ˆ
                    cookies = {}
                    for item in cookie_string.split(';'):
                        if '=' in item:
                            key, value = item.strip().split('=', 1)
                            cookies[key] = value
                    
                    if cookies.get('wr_vid'):
                        # ä½¿ç”¨ç›¸åŒçš„å®‰å…¨è§£ç å‡½æ•°
                        import urllib.parse
                        def safe_unquote(value: str) -> str:
                            if not value:
                                return ''
                            try:
                                decoded = urllib.parse.unquote(value, encoding='utf-8')
                                if decoded == value and '%' in value:
                                    decoded = urllib.parse.unquote(value, encoding='gbk', errors='ignore')
                                return decoded
                            except Exception:
                                return value
                        
                        user_info = {
                            'vid': cookies.get('wr_vid', ''),
                            'name': safe_unquote(cookies.get('wr_name', '')),
                            'avatar': safe_unquote(cookies.get('wr_avatar', '')),
                            'gender': cookies.get('wr_gender', ''),
                            'localvid': cookies.get('wr_localvid', ''),
                            'gid': cookies.get('wr_gid', ''),
                            'skey': cookies.get('wr_skey', ''),
                            'rt': cookies.get('wr_rt', '')
                        }
                        print(f"âš ï¸ CookieåŸºæœ¬éªŒè¯é€šè¿‡: {user_info['name']} (vid: {user_info['vid']})")
                        return True, "CookieåŸºæœ¬éªŒè¯é€šè¿‡", user_info
                    return False, f"å“åº”è§£æå¤±è´¥: {str(e)}", {}
            
            elif response.status_code == 401:
                return False, "Cookieå·²è¿‡æœŸæˆ–æ— æ•ˆ", {}
            elif response.status_code == 403:
                return False, "è®¿é—®è¢«æ‹’ç»ï¼Œå¯èƒ½éœ€è¦é‡æ–°ç™»å½•", {}
            else:
                return False, f"APIè¿”å›å¼‚å¸¸çŠ¶æ€ç : {response.status_code}", {}
                
        except requests.exceptions.Timeout:
            return False, "è¯·æ±‚è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥", {}
        except requests.exceptions.ConnectionError:
            return False, "æ— æ³•è¿æ¥åˆ°å¾®ä¿¡è¯»ä¹¦æœåŠ¡å™¨", {}
        except Exception as e:
            return False, f"éªŒè¯è¿‡ç¨‹å‡ºé”™: {str(e)}", {}
    
    def get_bookshelf_preview(self, cookie_string: str, vid: str) -> Tuple[bool, str, Dict]:
        """
        è·å–ä¹¦æ¶é¢„è§ˆä¿¡æ¯ï¼Œç”¨äºéªŒè¯Cookie
        ä½¿ç”¨æ›´æ–°çš„å¾®ä¿¡è¯»ä¹¦API
        """
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
                'Accept-Language': 'zh-CN,zh;q=0.9',
                'Accept-Encoding': 'gzip, deflate, br, zstd',
                'Sec-Ch-Ua': '"Chromium";v="140", "Not=A?Brand";v="24", "Google Chrome";v="140"',
                'Sec-Ch-Ua-Mobile': '?0',
                'Sec-Ch-Ua-Platform': '"Windows"',
                'Sec-Fetch-Dest': 'document',
                'Sec-Fetch-Mode': 'navigate',
                'Sec-Fetch-Site': 'same-origin',
                'Cookie': cookie_string,
                'Referer': 'https://weread.qq.com/',
            }
            
            # ä½¿ç”¨æ–°çš„web shelf APIè·å–ä¹¦æ¶ä¿¡æ¯
            url = f"https://weread.qq.com/web/shelf"
            response = requests.get(url, headers=headers, timeout=15, verify=False)
            
            if response.status_code == 200:
                try:
                    # æ£€æŸ¥å“åº”ç±»å‹
                    if 'text/html' in response.headers.get('content-type', ''):
                        # HTMLå“åº”ï¼Œè¿”å›åŸºç¡€ä¿¡æ¯
                        if 'bookshelf' in response.text or 'shelf' in response.text:
                            return True, "æˆåŠŸè®¿é—®ä¹¦æ¶é¡µé¢", {"books": [], "source": "web_shelf_html"}
                        else:
                            return False, "ä¹¦æ¶é¡µé¢è®¿é—®å¼‚å¸¸", {}
                    else:
                        # JSONå“åº”
                        data = response.json()
                        books_count = len(data.get('books', []))
                        return True, f"æˆåŠŸè·å–ä¹¦æ¶ä¿¡æ¯ï¼Œå…±{books_count}æœ¬ä¹¦", data
                except Exception as e:
                    # å³ä½¿è§£æå¤±è´¥ï¼Œ200çŠ¶æ€ç ä»è¡¨ç¤ºè®¿é—®æˆåŠŸ
                    return True, "ä¹¦æ¶è®¿é—®æˆåŠŸï¼ˆè§£æå¼‚å¸¸ï¼‰", {"books": [], "error": str(e)}
            else:
                return False, f"è·å–ä¹¦æ¶å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}", {}
                
        except Exception as e:
            return False, f"è·å–ä¹¦æ¶ä¿¡æ¯å¤±è´¥: {str(e)}", {}
    
    def format_cookie_for_api(self, cookies: Dict[str, str]) -> str:
        """
        æ ¼å¼åŒ–Cookieç”¨äºAPIè°ƒç”¨
        å‚è€ƒmcp-server-wereadçš„æ ¼å¼åŒ–æ–¹å¼
        """
        # ç¡®ä¿å¿…è¦å­—æ®µå­˜åœ¨
        formatted_cookies = {
            'wr_gid': cookies.get('wr_gid', ''),
            'wr_vid': cookies.get('wr_vid', ''),
            'wr_skey': cookies.get('wr_skey', ''),
            'wr_pf': '0',
            'wr_rt': cookies.get('wr_rt', ''),
            'wr_localvid': cookies.get('wr_localvid', ''),
            'wr_name': cookies.get('wr_name', ''),
            'wr_avatar': cookies.get('wr_avatar', ''),
            'wr_gender': cookies.get('wr_gender', '')
        }
        
        return '; '.join([f'{key}={value}' for key, value in formatted_cookies.items()])
    
    def extract_user_info(self, user_data: Dict) -> Dict[str, str]:
        """
        ä»ç”¨æˆ·æ•°æ®ä¸­æå–ç”¨æˆ·ä¿¡æ¯ï¼Œè¿›è¡Œé€‚å½“çš„æ•°æ®æ¸…ç†
        """
        import urllib.parse
        
        def safe_unquote(value: str) -> str:
            """å®‰å…¨åœ°è¿›è¡ŒURLè§£ç """
            if not value:
                return ''
            try:
                decoded = urllib.parse.unquote(value, encoding='utf-8')
                if decoded == value and '%' in value:
                    decoded = urllib.parse.unquote(value, encoding='gbk', errors='ignore')
                return decoded
            except Exception:
                return value
        
        result = {
            'wr_name': safe_unquote(user_data.get('name', '')),
            'wr_avatar': safe_unquote(user_data.get('avatar', '')),
            'wr_vid': str(user_data.get('vid', '')),
            'wr_gender': str(user_data.get('gender', 0)),
            'wr_localvid': user_data.get('localvid', ''),
            'wr_gid': user_data.get('gid', ''),
            'wr_skey': user_data.get('skey', ''),
            'wr_rt': user_data.get('rt', '')
        }
        
        print(f"ğŸ“‹ æå–ç”¨æˆ·ä¿¡æ¯å®Œæˆ: {result['wr_name']} (vid: {result['wr_vid']})")
        return result


# å…¨å±€Cookieç®¡ç†å™¨å®ä¾‹
cookie_manager = CookieManager()
